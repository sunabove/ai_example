{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34op2Q5-brL0",
        "outputId": "3391f3dd-7aae-4238-efb0-5cf1f49d1406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: librosa in c:\\users\\sunabove\\appdata\\roaming\\python\\python39\\site-packages (0.8.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in c:\\program files\\python39\\lib\\site-packages (from librosa) (1.7.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\sunabove\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\program files\\python39\\lib\\site-packages (from librosa) (21.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in c:\\users\\sunabove\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: joblib>=0.14 in c:\\users\\sunabove\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in c:\\program files\\python39\\lib\\site-packages (from librosa) (5.1.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in c:\\users\\sunabove\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: pooch>=1.0 in c:\\users\\sunabove\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in c:\\program files\\python39\\lib\\site-packages (from librosa) (1.20.3)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\users\\sunabove\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: numba>=0.43.0 in c:\\program files\\python39\\lib\\site-packages (from librosa) (0.54.1)\n",
            "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in c:\\program files\\python39\\lib\\site-packages (from numba>=0.43.0->librosa) (0.37.0)\n",
            "Requirement already satisfied: setuptools in c:\\program files\\python39\\lib\\site-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in c:\\program files\\python39\\lib\\site-packages (from packaging>=20.0->librosa) (2.4.7)\n",
            "Requirement already satisfied: appdirs in c:\\users\\sunabove\\appdata\\roaming\\python\\python39\\site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests in c:\\program files\\python39\\lib\\site-packages (from pooch>=1.0->librosa) (2.26.0)\n",
            "Requirement already satisfied: six>=1.3 in c:\\program files\\python39\\lib\\site-packages (from resampy>=0.2.2->librosa) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sunabove\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in c:\\program files\\python39\\lib\\site-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in c:\\program files\\python39\\lib\\site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python39\\lib\\site-packages (from requests->pooch>=1.0->librosa) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python39\\lib\\site-packages (from requests->pooch>=1.0->librosa) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\program files\\python39\\lib\\site-packages (from requests->pooch>=1.0->librosa) (1.26.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\program files\\python39\\lib\\site-packages (from requests->pooch>=1.0->librosa) (2.0.7)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: graphviz in c:\\users\\sunabove\\appdata\\roaming\\python\\python39\\site-packages (0.18.2)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
            "Requirement already satisfied: colorama in c:\\program files\\python39\\lib\\site-packages (from tqdm) (0.4.4)\n",
            "Installing collected packages: tqdm\n",
            "Successfully installed tqdm-4.62.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The script tqdm.exe is installed in 'C:\\Users\\sunabove\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "'apt-get' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# 1. Library install\n",
        "!pip install librosa\n",
        "!pip install graphviz\n",
        "!pip install tqdm\n",
        "\n",
        "!apt-get install graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SLXl1ufYbx3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python packages are imported.\n"
          ]
        }
      ],
      "source": [
        "# 2. import library\n",
        "\"\"\"'''\n",
        "os,glob : dir와 파일들에 접근하기 위한 Lib\n",
        "tensorflow, keras : 학습 및 모델 생성을 위한 Lib\n",
        "numpy : Matrix transpose 등 연산을 휘한 Lib\n",
        "librosa : feature extraction 및 음성 파일을 처리하기 위한 lib\n",
        "tqdm : iteration progress bar 생성 lib\n",
        "sklearn :scikit learn, machine learning을 지원해주는 lib\n",
        "'''\"\"\"\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "print( \"Python packages are imported.\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "58T1uCKXuK_z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python functions are defined.\n",
            "Parsing auto files from ./data/train ....\n",
            "sub_dir =  0-go\n",
            "sub_dir =  1-left\n",
            "sub_dir =  2-right\n",
            "sub_dir =  3-stop\n",
            "401 image files converted from audio file are saved.\n",
            "feature len =  401 feature[0] shape (100, 90)\n",
            "type(feature) =  <class 'list'> type(feature[0]) =  <class 'numpy.ndarray'>\n",
            "\n",
            "Parsing auto files from ./data/test ....\n",
            "sub_dir =  0-go\n",
            "sub_dir =  1-left\n",
            "sub_dir =  2-right\n",
            "sub_dir =  3-stop\n",
            "80 image files converted from audio file are saved.\n",
            "feature len =  80 feature[0] shape (100, 90)\n",
            "type(feature) =  <class 'list'> type(feature[0]) =  <class 'numpy.ndarray'>\n",
            "\n",
            "Extracting MFCC is finished.\n"
          ]
        }
      ],
      "source": [
        "# MFCC 추출 및 데이터 전처리(sklearn.preprocessing.scale)\n",
        "import sklearn.preprocessing \n",
        "from PIL import Image\n",
        "\n",
        "def mfcc_extract(filename):\n",
        "    y,sr  = librosa.load(filename,sr = 16000)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=100,n_fft=int(0.025*sr),hop_length=int(0.01*sr))\n",
        "\n",
        "    mfcc = sklearn.preprocessing.scale(mfcc, axis=1)\n",
        "    pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
        "    padded_mfcc = pad2d(mfcc, 90)\n",
        "    #librosa.display.specshow(padded_mfcc, sr=16000, x_axis='time')  #시각화하기\n",
        "\n",
        "    #delta=librosa.feature.delta(mfcc)\n",
        "    #delta2=librosa.feature.delta(mfcc,order=2)\n",
        "    #con_mfcc=np.concatenate((mfcc,delta,delta2),axis=0)\n",
        "    #print(y)\n",
        "    #print(len(y))\n",
        "    #print('Sampling rate (Hz): %d' %sr)\n",
        "    #print('Audio length (seconds): %.2f' % (len(y) / sr)) #음악의 길이(초) = 음파의 길이/Sampling rate\n",
        "    return padded_mfcc\n",
        "pass # -- mfcc_extract\n",
        "  \n",
        "# parse_audio_files는 parent_dir, sub_dirs를 변수로 받음\n",
        "# parent_dir 아래의 sub_dirs안에서 wav파일들을 읽고 mfcc feature를 추출 \n",
        "def parse_audio_files( data_dir ):\n",
        "    # 여기서는 MFCC 만 추출함, 레이블 데이터는 실제 학습시에 자동으로 부여함.\n",
        "    features = []\n",
        "    sub_dirs = os.listdir( data_dir )\n",
        "    \n",
        "    print( f\"Parsing auto files from {data_dir} ....\" )\n",
        "    \n",
        "    img_file_cnt = 0 \n",
        "    \n",
        "    for sub_dir in sub_dirs :\n",
        "        # 그냥 폴더 순서 대로 레이블을 지정함.\n",
        "        print( \"sub_dir = \", sub_dir  )        \n",
        "        \n",
        "        for fn in glob.glob(os.path.join( data_dir, sub_dir, \"*.wav\")):\n",
        "            #print mfcc_extract(fn).shape\n",
        "            features.append(mfcc_extract(fn)) \n",
        "\n",
        "            # 같은 폴더에 저장함.\n",
        "            # img, wav 폴더를 구분하지 않음.\n",
        "            fn_new = fn.replace('.wav','.png') \n",
        "            \n",
        "            plt.imsave( fn_new,  mfcc_extract(fn))\n",
        "            \n",
        "            img_file_cnt += 1\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "    print( f\"{img_file_cnt} image files converted from audio file are saved.\" )\n",
        "\n",
        "    return features \n",
        "pass # -- parse_audio_files\n",
        "\n",
        "print( \"Python functions are defined.\" )\n",
        "\n",
        "# File들로부터 feature를 추출\n",
        "# 모든 음성파일들은 1초이며 sampling rate는 160kHz, bit는 16bit이다. (확인필요!!! - https://melon1024.github.io/ssc/)\n",
        "# 따라서 mfcc feature들은 한 파일당 13*501의 형태를 가지게 된다.\n",
        "\n",
        "# train_cat의 내용을 확인\n",
        "# 학습 폴더 \n",
        "\n",
        "# Warning 메시지가 너무 많아서, 잠시 경고 메시지를 숨김\n",
        "# 데이터가 제대로 처리되지 못할 가능성도 있습니다.\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
        "\n",
        "# 학습 /테스트 데이터 MFCC 추출\n",
        "# 학습 폴더와 테스트 폴더의 MFCC 를 추출하여 png 이미지 파일도 저장한다.\n",
        "data_dirs = [ './data/train', './data/test' ] \n",
        "for data_dir in data_dirs : \n",
        "    features = parse_audio_files( data_dir ) \n",
        "\n",
        "    # features 확인 \n",
        "    # features는 python기본 타입 중 하나인 list이며 (13*501) ndarray를 원소로 가지고 있음\n",
        "\n",
        "    print( \"feature len = \", len(features), \"feature[0] shape\", features[0].shape)\n",
        "    print( \"type(feature) = \", type(features), \"type(feature[0]) = \", type(features[0]))\n",
        "    print()\n",
        "pass\n",
        "\n",
        "print( \"Extracting MFCC is finished.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwbc144Q4pV0"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB71s_U34qED"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29B9ZNOC4uex",
        "outputId": "a8b304c4-ad9e-4e82-dbab-8dc37813d40c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 401 images belonging to 4 classes.\n",
            "Found 80 images belonging to 4 classes.\n",
            "Epoch 1/50\n",
            "30/30 [==============================] - 4s 114ms/step - loss: -448.8201 - accuracy: 0.2268 - val_loss: -2144.2239 - val_accuracy: 0.2000\n",
            "Epoch 2/50\n",
            "30/30 [==============================] - 2s 76ms/step - loss: -9784.3447 - accuracy: 0.2612 - val_loss: -37556.4570 - val_accuracy: 0.3000\n",
            "Epoch 3/50\n",
            "30/30 [==============================] - 2s 70ms/step - loss: -83943.4766 - accuracy: 0.2612 - val_loss: -186947.8281 - val_accuracy: 0.1667\n",
            "Epoch 4/50\n",
            "30/30 [==============================] - 2s 69ms/step - loss: -354236.6875 - accuracy: 0.2200 - val_loss: -989847.4375 - val_accuracy: 0.3000\n",
            "Epoch 5/50\n",
            "30/30 [==============================] - 2s 68ms/step - loss: -1091693.1250 - accuracy: 0.2646 - val_loss: -1156867.5000 - val_accuracy: 0.2000\n",
            "Epoch 6/50\n",
            "30/30 [==============================] - 2s 67ms/step - loss: -3420149.7500 - accuracy: 0.2509 - val_loss: -3418534.5000 - val_accuracy: 0.1667\n",
            "Epoch 7/50\n",
            "30/30 [==============================] - 2s 69ms/step - loss: -5826349.0000 - accuracy: 0.2567 - val_loss: -5931540.5000 - val_accuracy: 0.2667\n",
            "Epoch 8/50\n",
            "30/30 [==============================] - 2s 65ms/step - loss: -11805019.0000 - accuracy: 0.2509 - val_loss: -18807442.0000 - val_accuracy: 0.2667\n",
            "Epoch 9/50\n",
            "30/30 [==============================] - 2s 67ms/step - loss: -21910888.0000 - accuracy: 0.2440 - val_loss: -25141122.0000 - val_accuracy: 0.3333\n",
            "Epoch 10/50\n",
            "30/30 [==============================] - 2s 71ms/step - loss: -32751268.0000 - accuracy: 0.2700 - val_loss: -68877232.0000 - val_accuracy: 0.2667\n",
            "Epoch 11/50\n",
            "30/30 [==============================] - 2s 71ms/step - loss: -49979944.0000 - accuracy: 0.2440 - val_loss: -97782760.0000 - val_accuracy: 0.2667\n",
            "Epoch 12/50\n",
            "30/30 [==============================] - 2s 65ms/step - loss: -80825696.0000 - accuracy: 0.2818 - val_loss: -133101840.0000 - val_accuracy: 0.2667\n",
            "Epoch 13/50\n",
            "30/30 [==============================] - 2s 70ms/step - loss: -105497952.0000 - accuracy: 0.2165 - val_loss: -120776552.0000 - val_accuracy: 0.3333\n",
            "Epoch 14/50\n",
            "30/30 [==============================] - 2s 67ms/step - loss: -136841712.0000 - accuracy: 0.2715 - val_loss: -127644880.0000 - val_accuracy: 0.3333\n",
            "Epoch 15/50\n",
            "30/30 [==============================] - 2s 66ms/step - loss: -182398880.0000 - accuracy: 0.2612 - val_loss: -167461520.0000 - val_accuracy: 0.3000\n",
            "Epoch 16/50\n",
            "30/30 [==============================] - 2s 72ms/step - loss: -270713248.0000 - accuracy: 0.2433 - val_loss: -200588656.0000 - val_accuracy: 0.2667\n",
            "Epoch 17/50\n",
            "30/30 [==============================] - 2s 71ms/step - loss: -321580992.0000 - accuracy: 0.2268 - val_loss: -446708960.0000 - val_accuracy: 0.2333\n",
            "Epoch 18/50\n",
            "30/30 [==============================] - 2s 69ms/step - loss: -439696096.0000 - accuracy: 0.2440 - val_loss: -615925056.0000 - val_accuracy: 0.1333\n",
            "Epoch 19/50\n",
            "30/30 [==============================] - 2s 73ms/step - loss: -559362240.0000 - accuracy: 0.2680 - val_loss: -713206784.0000 - val_accuracy: 0.2000\n",
            "Epoch 20/50\n",
            "30/30 [==============================] - 2s 77ms/step - loss: -748612864.0000 - accuracy: 0.2302 - val_loss: -592164288.0000 - val_accuracy: 0.2667\n",
            "Epoch 21/50\n",
            "30/30 [==============================] - 2s 70ms/step - loss: -902257280.0000 - accuracy: 0.2577 - val_loss: -1244414080.0000 - val_accuracy: 0.2333\n",
            "Epoch 22/50\n",
            "30/30 [==============================] - 2s 74ms/step - loss: -1095825024.0000 - accuracy: 0.2509 - val_loss: -1454286976.0000 - val_accuracy: 0.2000\n",
            "Epoch 23/50\n",
            "30/30 [==============================] - 2s 72ms/step - loss: -1469420032.0000 - accuracy: 0.2467 - val_loss: -1729260160.0000 - val_accuracy: 0.2333\n",
            "Epoch 24/50\n",
            "30/30 [==============================] - 2s 69ms/step - loss: -1557931264.0000 - accuracy: 0.2500 - val_loss: -2099625728.0000 - val_accuracy: 0.3333\n",
            "Epoch 25/50\n",
            "30/30 [==============================] - 2s 69ms/step - loss: -1703471616.0000 - accuracy: 0.2577 - val_loss: -1729627264.0000 - val_accuracy: 0.3333\n",
            "Epoch 26/50\n",
            "30/30 [==============================] - 2s 73ms/step - loss: -2412342528.0000 - accuracy: 0.2577 - val_loss: -4068679936.0000 - val_accuracy: 0.2000\n",
            "Epoch 27/50\n",
            "30/30 [==============================] - 2s 71ms/step - loss: -2667886848.0000 - accuracy: 0.2612 - val_loss: -2464341504.0000 - val_accuracy: 0.2667\n",
            "Epoch 28/50\n",
            "30/30 [==============================] - 2s 72ms/step - loss: -3043138048.0000 - accuracy: 0.2577 - val_loss: -2685721088.0000 - val_accuracy: 0.2667\n",
            "Epoch 29/50\n",
            "30/30 [==============================] - 2s 72ms/step - loss: -3525423104.0000 - accuracy: 0.2500 - val_loss: -3849323520.0000 - val_accuracy: 0.2667\n",
            "Epoch 30/50\n",
            "30/30 [==============================] - 2s 70ms/step - loss: -3943129856.0000 - accuracy: 0.2371 - val_loss: -3497605632.0000 - val_accuracy: 0.2333\n",
            "Epoch 31/50\n",
            "30/30 [==============================] - 2s 69ms/step - loss: -4372784640.0000 - accuracy: 0.2715 - val_loss: -3428108544.0000 - val_accuracy: 0.2333\n",
            "Epoch 32/50\n",
            "30/30 [==============================] - 2s 72ms/step - loss: -5473272832.0000 - accuracy: 0.2367 - val_loss: -6082146816.0000 - val_accuracy: 0.2000\n",
            "Epoch 33/50\n",
            "30/30 [==============================] - 2s 77ms/step - loss: -6381257728.0000 - accuracy: 0.2440 - val_loss: -6485621248.0000 - val_accuracy: 0.3000\n",
            "Epoch 34/50\n",
            "30/30 [==============================] - 2s 66ms/step - loss: -6790746624.0000 - accuracy: 0.2440 - val_loss: -7892522496.0000 - val_accuracy: 0.2333\n",
            "Epoch 35/50\n",
            "30/30 [==============================] - 2s 67ms/step - loss: -8200312832.0000 - accuracy: 0.2440 - val_loss: -8342209024.0000 - val_accuracy: 0.3000\n",
            "Epoch 36/50\n",
            "30/30 [==============================] - 2s 66ms/step - loss: -9105935360.0000 - accuracy: 0.2337 - val_loss: -8809256960.0000 - val_accuracy: 0.2333\n",
            "Epoch 37/50\n",
            "30/30 [==============================] - 2s 68ms/step - loss: -9901084672.0000 - accuracy: 0.2700 - val_loss: -16041580544.0000 - val_accuracy: 0.3333\n",
            "Epoch 38/50\n",
            "30/30 [==============================] - 2s 70ms/step - loss: -11929917440.0000 - accuracy: 0.2567 - val_loss: -6951923200.0000 - val_accuracy: 0.3000\n",
            "Epoch 39/50\n",
            "30/30 [==============================] - 2s 71ms/step - loss: -12077245440.0000 - accuracy: 0.2533 - val_loss: -6807369728.0000 - val_accuracy: 0.3000\n",
            "Epoch 40/50\n",
            "30/30 [==============================] - 2s 68ms/step - loss: -13154759680.0000 - accuracy: 0.2474 - val_loss: -13121045504.0000 - val_accuracy: 0.2000\n",
            "Epoch 41/50\n",
            "30/30 [==============================] - 2s 76ms/step - loss: -14680058880.0000 - accuracy: 0.2567 - val_loss: -17730785280.0000 - val_accuracy: 0.2667\n",
            "Epoch 42/50\n",
            "30/30 [==============================] - 2s 70ms/step - loss: -17233866752.0000 - accuracy: 0.2509 - val_loss: -13694929920.0000 - val_accuracy: 0.1667\n",
            "Epoch 43/50\n",
            "30/30 [==============================] - 2s 67ms/step - loss: -16686366720.0000 - accuracy: 0.2577 - val_loss: -24857567232.0000 - val_accuracy: 0.1667\n",
            "Epoch 44/50\n",
            "30/30 [==============================] - 2s 68ms/step - loss: -19723552768.0000 - accuracy: 0.2543 - val_loss: -22956980224.0000 - val_accuracy: 0.2333\n",
            "Epoch 45/50\n",
            "30/30 [==============================] - 2s 69ms/step - loss: -21152604160.0000 - accuracy: 0.2440 - val_loss: -28068173824.0000 - val_accuracy: 0.1333\n",
            "Epoch 46/50\n",
            "30/30 [==============================] - 2s 69ms/step - loss: -24668751872.0000 - accuracy: 0.2367 - val_loss: -19268005888.0000 - val_accuracy: 0.3000\n",
            "Epoch 47/50\n",
            "30/30 [==============================] - 2s 70ms/step - loss: -24422156288.0000 - accuracy: 0.2533 - val_loss: -26299211776.0000 - val_accuracy: 0.3000\n",
            "Epoch 48/50\n",
            "30/30 [==============================] - 2s 67ms/step - loss: -28668608512.0000 - accuracy: 0.2543 - val_loss: -22801002496.0000 - val_accuracy: 0.2667\n",
            "Epoch 49/50\n",
            "30/30 [==============================] - 2s 68ms/step - loss: -33278410752.0000 - accuracy: 0.2337 - val_loss: -26886121472.0000 - val_accuracy: 0.2667\n",
            "Epoch 50/50\n",
            "30/30 [==============================] - 2s 70ms/step - loss: -33243805696.0000 - accuracy: 0.2646 - val_loss: -35686715392.0000 - val_accuracy: 0.2333\n",
            "{'0-go': 0, '1-left': 1, '2-right': 2, '3-stop': 3}\n",
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        }
      ],
      "source": [
        "# Part 1 - Building the CNN \n",
        "# Importing the Keras libraries and packages\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (100, 90, 3), activation = 'relu'))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the CNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Part 2 - Fitting the CNN to the images\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory( './data/train',\n",
        "                                                 target_size = (100, 90),\n",
        "                                                 batch_size = 10,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory( './data/test',\n",
        "                                            target_size = (100, 90),\n",
        "                                            batch_size = 10,\n",
        "                                            class_mode = 'binary')\n",
        "\n",
        "# 데이터를 무작위로 섞는다.???? 넣으면 오류나나\n",
        "#import random\n",
        "#random.shuffle(training_set)\n",
        "#random.shuffle(test_set)\n",
        "\n",
        "classifier.fit(training_set,\n",
        "                steps_per_epoch = 30,\n",
        "                epochs = 50,\n",
        "                validation_data = test_set,\n",
        "                validation_steps = 3)\n",
        "\n",
        "output = classifier.predict(test_set, steps=5)\n",
        "print(test_set.class_indices)\n",
        "print(output)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "음성인식20211122.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f6363e3aeaf4c658325eb43c5ac562b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_225c5c8a6c754ed7802e459e741df4c4",
            "placeholder": "​",
            "style": "IPY_MODEL_997fa0274f2c4ec3bdb9082bbfef32a7",
            "value": "100%"
          }
        },
        "1f9e26c2720b49e7918263b941f4e5ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "225c5c8a6c754ed7802e459e741df4c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "707f9774bbb44e2993bb67c2d225d370": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f6363e3aeaf4c658325eb43c5ac562b",
              "IPY_MODEL_e1b1fce68b0146609dbfdc479e6853a3",
              "IPY_MODEL_fb055349a2f54fc28f6b98e56b824e8d"
            ],
            "layout": "IPY_MODEL_7261b21b251c49c99855b96a8bc0c071"
          }
        },
        "7261b21b251c49c99855b96a8bc0c071": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99160c25478941ceb890d4611aa1b7c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "997fa0274f2c4ec3bdb9082bbfef32a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1cff9ae9c5840ab82b8a52768f554bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1b1fce68b0146609dbfdc479e6853a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f9e26c2720b49e7918263b941f4e5ae",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea20d15d64234c5ab2a71d97ee0bead4",
            "value": 1
          }
        },
        "ea20d15d64234c5ab2a71d97ee0bead4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb055349a2f54fc28f6b98e56b824e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99160c25478941ceb890d4611aa1b7c9",
            "placeholder": "​",
            "style": "IPY_MODEL_d1cff9ae9c5840ab82b8a52768f554bb",
            "value": " 1/1 [01:06&lt;00:00, 66.85s/it]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
